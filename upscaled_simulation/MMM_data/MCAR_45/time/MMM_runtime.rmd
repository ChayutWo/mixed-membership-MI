
---
title: "Mixed Membership Model for MI - Simulation example with 45% MCAR"
output:
  pdf_document: default
  html_document:
    highlight: pygments
    theme: spacelab
---

```{r setup, echo =FALSE, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, fig.pos = 'h', fig.align = 'center')
knitr::opts_chunk$set(fig.cap = "",  fig.path = "Plot")
library(knitr)
library(dplyr)
library(arm)
library(pROC)
library(tidyverse)
library(MASS)
library(tigerstats)
library(leaps)
library(car)
library(rms)
require(caret)
require(e1071)
library(lme4) 
library(lattice)
library(broom)
library(boot)
library(ggplot2)
library(cobalt)
require(tidyverse)
require(rstanarm)
require(magrittr)
require(rstan)
require(MCMCpack)
library(abind)
library(matrixStats)
library(truncnorm)
library(mvtnorm)
library(MCMCpack)
library(mnormt)
library(coda)
library(DirichletReg)
```

* * *
### Generate small dataset

Settings 
- N = 2500 surveyed subjects
- K = 5 clusters
- p = 5 questions/variables
- d1 = 2 choices, d2 = d3 = d4 = 3 choices, d5 = 5 choices
- $\gamma$ = 2 and $\alpha_0$ = 1 for DP generative process

Generative process
- $\beta|\gamma \sim GEM(\gamma)$
- $\pi_i|\alpha_0 \sim DP(\alpha_0, \beta)$ for i = 1,...,N
- $z_{ij}|\pi_i \sim Cat(\pi_i)$ for i = 1,...,N and j = 1,...,p
- $x_{ij}|z_{ij}=k \sim Cat(\Phi^{(j)}_k)$ for i = 1,...,N and j=1,...,p

```{r}
set.seed(1)
# parameter setup
N = 2500 # number of surveyed subjects
K_true = 5 # number of true clusteres
p = 5 # number of survey questions
d1 = 2 # number of levels of 1st variable
d2 = 3 # number of levels of 2st variable
d3 = 3 # number of levels of 3st variable
d4 = 3
d5 = 5
gamma_true = 2
alpha_true = 1
level = c(d1, d2, d3, d4, d5)

# place holder
Phi_1 = matrix(NA, nrow = K_true, ncol = d1) # multinomial parameter for 1st variable
Phi_2 = matrix(NA, nrow = K_true, ncol = d2) # multinomial parameter for 2nd variable
Phi_3 = matrix(NA, nrow = K_true, ncol = d3) # multinomial parameter for 3rd variable
Phi_4 = matrix(NA, nrow = K_true, ncol = d4) # multinomial parameter for 4th variable
Phi_5 = matrix(NA, nrow = K_true, ncol = d5) # multinomial parameter for 5th variable
```

```{r}
# Phi parameter for different clusters and different variables
# size #clusterx#levels

# 1st variable (d1 = 2)
Phi_1[,1] = c(0.1, 0.3, 0.5, 0.7, 0.9)
Phi_1[,2] = 1 - Phi_1[,1]

# 2nd variable (d2 = 3)
Phi_2[,1] = c(0.1, 0.1, 0.8, 0.25, 0.5)
Phi_2[,2] = c(0.1, 0.8, 0.1, 0.5, 0.25)
Phi_2[,3] = 1 - Phi_2[,1] - Phi_2[,2]

# 3rd variable (d3 = 3)
Phi_3[,1] = c(0.1, 0.8, 0.1, 0.25, 0.25)
Phi_3[,2] = c(0.8, 0.1, 0.1, 0.25, 0.5)
Phi_3[,3] = 1 - Phi_3[,1] - Phi_3[,2]

# 4th variable (d4 = 3)
Phi_4[,1] = c(0.8, 0.1, 0.1, 0.5, 0.25)
Phi_4[,2] = c(0.1, 0.1, 0.8, 0.25, 0.5)
Phi_4[,3] = 1 - Phi_4[,1] - Phi_4[,2]

# 5th variable (d5= 5)
Phi_5[,1] = c(0.5, 0.1, 0.1, 0.1, 0.2)
Phi_5[,2] = c(0.2, 0.5, 0.1, 0.1, 0.1)
Phi_5[,3] = c(0.1, 0.2, 0.5, 0.1, 0.1)
Phi_5[,4] = c(0.1, 0.1, 0.2, 0.5, 0.1)
Phi_5[,5] = 1 - Phi_5[,1] - Phi_5[,2] - Phi_5[,3] - Phi_5[,4]

Phi = list(Phi_1, Phi_2, Phi_3, Phi_4, Phi_5)
```

```{r}
# Beta ~ GEM(gamma_true)
Beta_true = array(NA, dim = K_true)
V = array(NA, K_true)
V[K_true] = 1
prod = 1 # product of (1-V_l) for l<k
# Sample V_k from k = 1,...,K-1
for (k in 1:(K_true - 1)) {
  V[k] = rbeta(1, 1, gamma_true) # Vk ~ Beta(1, gamma)
  Beta_true[k] = V[k]*prod
  prod = prod*(1-V[k])
}
Beta_true[K_true] = 1-sum(Beta_true[1:(K_true-1)])
```

```{r}
# Pi_i ~ DP(alpha_true, Beta_true) for i = 1,...,N
Pi_true = matrix(NA, N, K_true)
u = matrix(NA, N, K_true)
u[,K_true] = 1
prod = array(1, N) # product of (1-u_il) for l<k
# sample u_ik ~ Beta distribution
# then, obtain Pi from u
for (k in 1:(K_true - 1)) {
  u[,k] = rbeta(N, alpha_true*Beta_true[k], alpha_true*(1-sum(Beta_true[1:k])))
  Pi_true[,k] = u[,k]*prod
  prod = prod*(1-u[,k])
}
Pi_true[,K_true] = 1-rowSums(Pi_true[,1:(K_true-1)])
```

```{r}
# Check the mean of Pi from DP
cat('Beta:', Beta_true,'\n')
cat('Pi:', apply(Pi_true, MARGIN = 2, FUN = mean))
```

```{r}
# Sample cluster assignment z_ij ~ Cat(Pi_i)
# Sample observation x_ij|z_ij=k ~ Cat(Phi_jk)
z_true = matrix(NA, nrow = N, ncol = p) # true cluster assignment
X = matrix(NA, nrow = N, ncol = p) # data matrix
for (i in 1:N) {
  z_true[i,] = sample(1:K_true, p, replace=TRUE, prob=Pi_true[i,])
  for (j in 1:p) {
    z = z_true[i,j]
    prob = Phi[[j]][z,]
    X[i,j] = sample(1:length(prob), 1, replace = TRUE, prob = prob)
  }
}

# format variables of X to be factor
X = data.frame(X)
for (col_index in 1:ncol(X)) {
  X[,col_index] = factor(X[,col_index], levels = 1:level[col_index])
}
```

```{r}
# make MCAR
missing_prob = 0.45
X_miss = X
for (col in 1:ncol(X)) {
    missing_ind <- rbernoulli(N, p = missing_prob)
    X_miss[missing_ind, col] <- NA
}
R = is.na(X_miss)
# initial imputation
for (col in 1:ncol(X)) {
    missing_ind <- R[,col]
    X_miss[missing_ind, col] <- sample(1:level[col], size = sum(missing_ind),
                                       table(X_miss[R[,col]!=1,col]), replace = TRUE)
}
```

### Visualization

```{r}
barplot(table(z_true)/N/p, main = 'cluster assignment: z', ylim = c(0,1))
```

```{r}
# 1st variable
var = 1
barplot(table(X[,var])/N, main = 'overall')
for (z in 1:K_true) {
  barplot(table(X[z_true[,var]==z,var])/sum(table(X[z_true[,var]==z,var])), 
        main = paste('variable:',var,'/', 'cluster:',z), ylim = c(0,1))
}
```

```{r}
# 2nd variable
var = 2
barplot(table(X[,var])/N, main = 'overall')
for (z in 1:K_true) {
  barplot(table(X[z_true[,var]==z,var])/sum(table(X[z_true[,var]==z,var])), 
        main = paste('variable:',var,'/', 'cluster:',z), ylim = c(0,1))
}
```

```{r}
# 3rd variable
var = 3
barplot(table(X[,var])/N, main = 'overall')
for (z in 1:K_true) {
  barplot(table(X[z_true[,var]==z,var])/sum(table(X[z_true[,var]==z,var])), 
        main = paste('variable:',var,'/', 'cluster:',z), ylim = c(0,1))
}
```

```{r}
# 4th variable
var = 4
barplot(table(X[,var])/N, main = 'overall')
for (z in 1:K_true) {
  barplot(table(X[z_true[,var]==z,var])/sum(table(X[z_true[,var]==z,var])), 
        main = paste('variable:',var,'/', 'cluster:',z), ylim = c(0,1))
}
```

```{r}
# 5th variable
var = 5
barplot(table(X[,var])/N, main = 'overall')
for (z in 1:K_true) {
  barplot(table(X[z_true[,var]==z,var])/sum(table(X[z_true[,var]==z,var])), 
        main = paste('variable:',var,'/', 'cluster:',z), ylim = c(0,1))
}
```

### Mixed-Membership Model (MMM) MCMC

```{r}
set.seed(1)
# MCMC variables
Mon = 1000
burnin = 500
thining = 10

N = dim(X)[1]
K = 60
p = dim(X)[2]
# hyperprior parameters
# gamma ~ Gamma(a,b)
a = 0.25
b = 0.25
# alpha0 ~ Gamma(c,d)
c = 0.25
d = 0.25
# storage
GAMMA = rep(NA, (Mon-burnin)/thining)
ALPHA0 = rep(NA, (Mon-burnin)/thining)
BETA = matrix(NA, nrow = (Mon-burnin)/thining, ncol = K)
PI = array(NA, c(N, K, (Mon-burnin)/thining))
Z = array(NA, c(N, p, (Mon-burnin)/thining))
X_SAMPLE = array(NA, c(N, p, (Mon-burnin)/thining))
PHI1 = array(NA, c(K, d1, (Mon-burnin)/thining))
PHI2 = array(NA, c(K, d2, (Mon-burnin)/thining))
PHI3 = array(NA, c(K, d3, (Mon-burnin)/thining))
PHI4 = array(NA, c(K, d4, (Mon-burnin)/thining))
PHI5 = array(NA, c(K, d5, (Mon-burnin)/thining))
```

```{r}
# initialization for x
x_temp = X_miss

# initialization for z
z_temp = data.frame(matrix(sample(1:K, size = N*p, replace = TRUE), nrow = N, ncol = p))
for (col_index in 1:ncol(z_temp)) {
  z_temp[,col_index] = factor(z_temp[,col_index], levels = 1:K)
}
# nik = # of variables in cluster k for observation i
nik = matrix(NA, N, K)
for (k in 1:K) {
  nik[,k] = rowSums(z_temp==k)
}
# initialization for PHI
phi_temp = list()
for (j in 1:p) {
  prob = rdirichlet(n = K, rep(1,level[j])) # Kxlevel matrix
  phi_temp[[j]] = prob
}
# initialization for gamma and alpha0
gamma_temp = 1
alpha0_temp = 1 

# initialization for Vk and Betak
# Beta ~ GEM(gamma_temp)
# Sample Vk ~ Beta(1, gamma)
Vk_temp <- matrix(rbeta(K-1,1,gamma_temp),nrow=K-1)
Vk_temp <- rbind(Vk_temp,1)
one_min_Vk_temp <- 1L-Vk_temp
one_min_Vk_temp <- c(1,cumprod(one_min_Vk_temp[1:(K-1)]))
# Compute Betak for k = 1,...,K
beta_temp <- Vk_temp*one_min_Vk_temp

# initialization for u and Pi
# Pi_i ~ DP(alpha_temp, Beta_temp) for i = 1,...,N
one_min_cumsum_beta_temp <-1L-cumsum(beta_temp[1:(K-1)])
one_min_cumsum_beta_temp[one_min_cumsum_beta_temp<=0] <- 1.0e-20
u_temp <- matrix(rbeta(N*(K-1),alpha0_temp*rep(beta_temp[1:(K-1)],each=N),
                       alpha0_temp*rep(one_min_cumsum_beta_temp,each=N) ),
                 nrow=N,ncol=(K-1),byrow = F)
# Prevent instability issue
u_temp[u_temp==1] = 0.99999; u_temp[u_temp==0] = 1.0e-5
u_temp <- cbind(u_temp,1)
one_min_u_temp <- 1L-u_temp
one_min_u_temp <- cbind(1,t(apply(one_min_u_temp[,-K],1,cumprod)))
# Compute Pi from uik
Pi_temp <- u_temp*one_min_u_temp

# initialization for auxiliary variables
t_temp = array(NA, N)
sik = matrix(0, N, K)

# matrix used in MCMC
nik = matrix(NA, N, K)
```

```{r}
z_time = 0
nik_time = 0
phi_time = 0
aux_time = 0
beta_time = 0
pi_time = 0
gamma_time = 0
alpha_time = 0
impute_time = 0
```

```{r}
id = 0
for (trial in 1:Mon) {
  # Step 1: Update z_ij
  start = Sys.time()
  for (j in 1:p) {
    # get phi_j
    prob = phi_temp[[j]]
    var = x_temp[,j]
    likelihood = t(prob[,var]) # NxK of phi_j_xij
    full_prob_matrix = Pi_temp*likelihood
    full_prob_matrix <- full_prob_matrix/matrix(rowSums(full_prob_matrix),nrow=N,ncol=K) # normalize
    Ran_unif <- runif(N)
    cumul <- full_prob_matrix%*%upper.tri(diag(ncol(full_prob_matrix)),diag=TRUE)
    z_temp[,j] <- factor(rowSums(Ran_unif>cumul) + 1L, levels = 1:K)
  }
  z_time = z_time + (Sys.time() - start)
  
  # update nik
  start = Sys.time()
  for (k in 1:K) {
    nik[,k] = rowSums(z_temp==k)
  }
  # for each row, factor it and find frequency using table
  #nik = t(apply(z_temp, 1, function(x) table(factor(x,levels=1:K))))
  nik_time = nik_time + (Sys.time() - start)
  
  # Step 2: Update Phi_k
  start = Sys.time()
  for (j in 1:p) {
    contingency_table = table(z_temp[,j], x_temp[,j])
    phi_temp[[j]] = DirichletReg::rdirichlet(K,1+contingency_table)
  }
  phi_time = phi_time + (Sys.time() - start)
  
  # Step 3: Update Vk and betak
  # sample auxiliary variable ti
  start = Sys.time()
  t_temp = rbeta(N,alpha0_temp,rowSums(nik))
  sik = matrix(0, N, K)
  for (i in 1:N) {
    # sample auxiliary variable sik
    for (k in 1:K) {
      if (nik[i,k]==0) {
        sik[i,k]=0
      }else{
        prob = (alpha0_temp*beta_temp[k])/(alpha0_temp*beta_temp[k]+1:(nik[i,k])-1)
        sik[i,k] = sum(rbernoulli(nik[i,k], prob))
      }
    }
  }
  aux_time = aux_time + (Sys.time() - start)
  
  # sample Vk for k = 1,...,K-1
  start = Sys.time()
  Vk_temp[1:(K-1)] <- rbeta((K-1),(1L+colSums(sik[,1:(K-1)])),
                            (gamma_temp + (sum(sik) - cumsum(colSums(sik)))[1:K-1]) )
  # Prevent instability issue
  Vk_temp[Vk_temp==1] <- 0.99999; Vk_temp[Vk_temp==0] <- 1.0e-5
  Vk_temp[K] <- 1
  one_min_Vk_temp <- 1L-Vk_temp
  one_min_Vk_temp <- c(1,cumprod(one_min_Vk_temp[1:(K-1)]))
  # compute betak for k = 1,...,K
  beta_temp <- Vk_temp*one_min_Vk_temp
  if (sum(beta_temp<0)>0) {
    print('error with beta < 0')
  }
  beta_time = beta_time + (Sys.time() - start)
  
  # Step 4: Update u_ik and pi_ik
  start = Sys.time()
  one_min_cumsum_beta_temp <- 1L-cumsum(beta_temp[1:(K-1)])
  # Prevent instability issue
  one_min_cumsum_beta_temp[one_min_cumsum_beta_temp<=0] <- 1.0e-20
  u_temp[,1:(K-1)] <- matrix(rbeta( (N*(K-1)), (alpha0_temp*rep(beta_temp[1:(K-1)],each=N) + c(nik[,1:(K-1)]) ) ,
                         (alpha0_temp*rep(one_min_cumsum_beta_temp,each=N) +
                            c(matrix(rowSums(nik),ncol=K-1,nrow=N)-t(apply(nik,1,cumsum))[,1:K-1]) ) ),
                         nrow=N,ncol=(K-1),byrow = F)
  # Prevent instability issue
  u_temp[u_temp==1] = 0.99999; u_temp[u_temp==0] = 1.0e-5
  u_temp[,K] <- 1
  one_min_u_temp <- 1L-u_temp
  one_min_u_temp <- cbind(1,t(apply(one_min_u_temp[,-K],1,cumprod)))
  Pi_temp <- u_temp*one_min_u_temp
  pi_time = pi_time + (Sys.time() - start)
  
  # Step 5.1: Update gamma
  start = Sys.time()
  gamma_temp = rgamma(1, a + K - 1, b - sum(log(1-Vk_temp[1:(K-1)])))
  gamma_time = gamma_time + (Sys.time() - start)
  # Step 5.2: Update alpha
  start = Sys.time()
  alpha0_temp = rgamma(1, c + sum(sik), d - sum(log(t_temp)))
  alpha_time = alpha_time + (Sys.time() - start)
  
  # Step 6: Update x_ij
  start = Sys.time()
  for (j in 1:p) {
    # get z_ij for missing entries
    missing_idx = (R[,j] == 1)
    z_cur = z_temp[missing_idx,j]
    # get phi_ij
    prob = phi_temp[[j]][z_cur,] # number of missing entries x dj matrix
    prob_cum = prob%*%upper.tri(diag(ncol(prob)),diag=TRUE)
    Ran_unif <- runif(sum(missing_idx))
    x_temp[missing_idx, j] = rowSums(Ran_unif>prob_cum) + 1L
  }
  
  impute_time = impute_time + (Sys.time() - start)
  # Save posterior samples
  if ((trial>burnin) && ((trial-burnin)%%thining==1) ) {
    id = id + 1
    GAMMA[id] = gamma_temp
    ALPHA0[id] = alpha0_temp
    BETA[id,] = beta_temp
    PI[,,id] = Pi_temp
    Z[,,id] = data.matrix(z_temp)
    X_SAMPLE[,,id] = data.matrix(x_temp)
    PHI1[,,id] = phi_temp[[1]]
    PHI2[,,id] = phi_temp[[2]]
    PHI3[,,id] = phi_temp[[3]]
    PHI4[,,id] = phi_temp[[4]]
    PHI5[,,id] = phi_temp[[5]]
  }
  print(paste('finish runing MCMC trial:',trial))
}
```

### Posterior Diagnostics

```{r, echo = FALSE}
gamma.mcmc <- mcmc(GAMMA, start = 1)
summary(gamma.mcmc)
plot(gamma.mcmc)
autocorr.plot(gamma.mcmc)
```

```{r}
alpha0.mcmc <- mcmc(ALPHA0, start = 1)
summary(alpha0.mcmc)
plot(alpha0.mcmc)
autocorr.plot(alpha0.mcmc)
```

```{r}
# Convergence checking Beta a after accounting for burnin and thining
beta_df = BETA
colnames(beta_df) <- 1:K
matplot(1:dim(beta_df)[1], beta_df, 
        type = 'l', ylab = 'Beta_k', xlab = 'trials', 
        main = 'Checking stability of sampled Beta')

```

```{r}
# Check number of active cluster 
Z_df = Z
active_cluster = array(0, dim(Z_df)[3])
for (idx in 1:dim(active_cluster)) {
  for (k in 1:K) {
    if (sum(Z_df[,,idx]==k)!=0) {
      active_cluster[idx] = active_cluster[idx] + 1
    }
  }
}
plot(1:dim(active_cluster), active_cluster, type = 'l', ylab = 'Number of active clusters',
     xlab = 'trials', main = 'Checking number of active clusters during MCMC', ylim = c(1,K))

```


```{r, fig.width=3, fig.height=2}
# Convergence checking for Phi1
for (k in 1:K) {
  phi_df = cbind(PHI1[k,1,], 
                 PHI1[k,2,])
  colnames(phi_df) = c('d=1', 'd=2')
  matplot(1:dim(phi_df)[1], phi_df, 
          type = 'l', ylab = 'phi', xlab = 'trials', 
          main = paste('Checking stability of sampled phi1: K=',k), ylim = c(0,1),
          col = c('black', 'green'), lty = 1:2, lwd = 1)
  legend('right', legend = colnames(phi_df), col = c('black', 'green'), lty = 1:2, lwd = 1)
}
```

```{r}
# Convergence checking for Phi2
for (k in 1:K) {
  phi_df = cbind(PHI2[k,1,], 
                 PHI2[k,2,],
                 PHI2[k,3,])
  colnames(phi_df) = c('d=1', 'd=2', 'd=3')
  matplot(1:dim(phi_df)[1], phi_df, 
          type = 'l', ylab = 'phi', xlab = 'trials', 
          main = paste('Checking stability of sampled phi2: K=',k), ylim = c(0,1), 
          col = c('black', 'green', 'red'), lty = 1:3, lwd = 1)
  legend('right', legend = colnames(phi_df), col = c('black', 'green', 'red'), lty = 1:3, lwd = 1)
}
```

```{r}
# Convergence checking for Phi3
for (k in 1:K) {
  phi_df = cbind(PHI3[k,1,], 
                 PHI3[k,2,],
                 PHI3[k,3,])
  colnames(phi_df) = c('d=1', 'd=2', 'd=3')
  matplot(1:dim(phi_df)[1], phi_df, 
          type = 'l', ylab = 'phi', xlab = 'trials', 
          main = paste('Checking stability of sampled phi3: K=',k), ylim = c(0,1), 
          col = c('black', 'green', 'red'), lty = 1:3, lwd = 1)
  legend('right', legend = colnames(phi_df), col = c('black', 'green', 'red'), lty = 1:3, lwd = 1)
}
```

```{r}
# Convergence checking for Phi4
for (k in 1:K) {
  phi_df = cbind(PHI4[k,1,], 
                 PHI4[k,2,],
                 PHI4[k,3,])
  colnames(phi_df) = c('d=1', 'd=2', 'd=3')
  matplot(1:dim(phi_df)[1], phi_df, 
          type = 'l', ylab = 'phi', xlab = 'trials', 
          main = paste('Checking stability of sampled phi4: K=',k), ylim = c(0,1), 
          col = c('black', 'green', 'red'), lty = 1:3, lwd = 1)
  legend('right', legend = colnames(phi_df), col = c('black', 'green', 'red'), lty = 1:3, lwd = 1)
}
```

```{r}
# Convergence checking for Phi5
for (k in 1:K) {
  phi_df = cbind(PHI5[k,1,], 
                 PHI5[k,2,],
                 PHI5[k,3,],
                 PHI5[k,4,],
                 PHI5[k,5,])
  colnames(phi_df) = c('d=1', 'd=2', 'd=3', 'd=4', 'd=5')
  matplot(1:dim(phi_df)[1], phi_df, 
          type = 'l', ylab = 'phi', xlab = 'trials', 
          main = paste('Checking stability of sampled phi5: K=',k), ylim = c(0,1), 
          col = c('black', 'green', 'red', 'blue', 'yellow'), lty = 1:5, lwd = 1)
  legend('right', legend = colnames(phi_df), col = c('black', 'green', 'red', 'blue', 'yellow'), 
         lty = 1:5, lwd = 1)
}
```

```{r}
# Compare predictive distribution with true marginal distribution and posterior samples
X_POST = X_SAMPLE

```

```{r}
X_df = data.frame(X)
for (n_way in 1:3) {
  combinations = combn(1:p, n_way)

  # calculate true pmf without missingness
  true_pmf = c()
  for (i in 1:(dim(combinations)[2])) {
    variables = combinations[, i]
    true_pmf_temp = table(X_df[,variables])
    true_pmf_temp = c(true_pmf_temp/sum(true_pmf_temp))
    true_pmf = c(true_pmf, true_pmf_temp)
  }
  
  # calculate imputed pmf
  imputed_pmf = c()
  for (t in 1:(dim(X_POST)[3])) {
    # for each imputed dataset, calculate joint pmf
    X_POST_df = data.frame(X_POST[,,t])
    imputed_pmf_temp = c()
    for (i in 1:(dim(combinations)[2])) {
      variables = combinations[, i]
      imputed_pmf_temp = c(imputed_pmf_temp, c(table(X_POST_df[,variables])/sum(table(X_POST_df[,variables]))))
    }
    # imputed_pmf has dimension #samples x #pmfs
    imputed_pmf = rbind(imputed_pmf, imputed_pmf_temp)
  }
  
  # calculate mean and 95% credible interval
  imputed_pmf_mean = apply(imputed_pmf, MARGIN = 2, FUN = mean)
  imputed_pmf_ci = apply(imputed_pmf, MARGIN = 2, FUN = quantile, probs = c(0.025, 0.975))
  pmf_df <- data.frame(true_pmf,imputed_pmf_mean, imputed_pmf_ci[1,], imputed_pmf_ci[2,])
  names(pmf_df) <- c('true_pmf', "expectation","Q2.5", "Q97.5")
  
  # Calculate coverage
  lower_bound = imputed_pmf_ci[1,]
  upper_bound = imputed_pmf_ci[2,]
  coverage = (lower_bound<=true_pmf) & (true_pmf<=upper_bound)
  
  
  # Make a plot
  title = paste('True pmf vs Imputed pmf: n_way', n_way, 
                ', coverage', round(mean(coverage),2))
  plt <- ggplot(data = pmf_df, aes(x = true_pmf, y = expectation))+
    geom_pointrange(aes(ymin = Q2.5, ymax = Q97.5), size = 0.4, alpha = 0.6, colour = 'blue')+
    geom_abline(intercept = 0, slope = 1, colour = 'red', alpha = 0.2)+
    scale_x_continuous("true pmf", breaks = seq(0, 1, 0.05)) +
    scale_y_continuous(expression('imputed pmf')) +
    ggtitle(title)
  show(plt)
  
  plt <- ggplot(data = pmf_df, aes(x = true_pmf, y = expectation))+
    geom_point(size = 1, alpha = 0.7, colour = 'blue')+
    geom_abline(intercept = 0, slope = 1, colour = 'red', alpha = 0.5)+
    scale_x_continuous("true pmf", breaks = seq(0, 1, 0.05)) +
    scale_y_continuous(expression('imputed pmf')) +
    ggtitle(title)
  show(plt)
  print(dim(pmf_df))
  
  
  # make coverage plot
  title = paste('95% CI: n_way', n_way, 
                ', coverage', round(mean(coverage),2))
  PredCI_col <- ifelse(coverage==1,"lightblue3","red4")
  PredCI_lwd <- ifelse(coverage==1,1,2)
  plot(pmf_df[,1], pch=4, ylim=range(pretty(c(pmf_df[,3], pmf_df[,4]))),
       xlab="Index", ylab="Joint probabilities", las=1,col="orange4",
       main=title)
  segments(seq_len(length(pmf_df[,1])), pmf_df[,3], y1=pmf_df[,4], lend=1,
           lwd=PredCI_lwd,col=PredCI_col)
  points(pmf_df[,3], pch="-", bg=PredCI_col); points(pmf_df[,4], pch="-", bg=PredCI_col)
  legend("topright", inset=.05, bty="n",
         legend=c("Intervals containing true pmf",
                  "Intervals NOT containing true pmf","true joint probabilities"),
         lwd=c(1,2,1), lty=c(1,1,NA),pch=c(NA,NA,4), col=c("lightblue3","red4","orange4"))
}
```

```{r}
# subsample for trivariate distribution
idx = seq(1, dim(pmf_df)[1], 5)
# Make a plot
title = paste('True pmf vs Imputed pmf: n_way', n_way, 
              ', coverage', round(mean(coverage),2))
plt <- ggplot(data = pmf_df[idx,], aes(x = true_pmf, y = expectation))+
  geom_point(size = 1, alpha = 0.7, colour = 'blue')+
  geom_abline(intercept = 0, slope = 1, colour = 'red', alpha = 0.5)+
  scale_x_continuous("true pmf", breaks = seq(0, 1, 0.05)) +
  scale_y_continuous(expression('imputed pmf')) +
  ggtitle(title)
show(plt)


# make coverage plot
title = paste('95% CI: n_way', n_way, 
              ', coverage', round(mean(coverage),2))
PredCI_col <- ifelse(coverage[idx]==1,"lightblue3","red4")
PredCI_lwd <- ifelse(coverage[idx]==1,1,2)
plot(pmf_df[idx,1], pch=4, ylim=range(pretty(c(pmf_df[idx,3], pmf_df[idx,4]))),
     xlab="Index", ylab="Joint probabilities", las=1,col="orange4",
     main=title)
segments(seq_len(length(pmf_df[idx,1])), pmf_df[idx,3], y1=pmf_df[idx,4], lend=1,
         lwd=PredCI_lwd,col=PredCI_col)
points(pmf_df[idx,3], pch="-", bg=PredCI_col); points(pmf_df[idx,4], pch="-", bg=PredCI_col)
legend("topright", inset=.05, bty="n",
       legend=c("Intervals containing true pmf",
                "Intervals NOT containing true pmf","true joint probabilities"),
       lwd=c(1,2,1), lty=c(1,1,NA),pch=c(NA,NA,4), col=c("lightblue3","red4","orange4"))
```


```{r}
# evaluate runtime
total_time = z_time + nik_time + phi_time + aux_time + beta_time + pi_time + 
  gamma_time + alpha_time + impute_time
data = as.numeric(c(z_time, nik_time, phi_time, aux_time, beta_time, pi_time, 
                    gamma_time, alpha_time, impute_time))/as.numeric(total_time)
names(data) = c('z', 'nik', 'phi', 'aux', 'beta', 'pi', 'gamma', 'alpha', 'impute')
barplot(data, ylab = 'runtime portion', legend = TRUE, 
        main = 'Runtime comparison for different parts of MCMC', ylim = c(0,1))

print(paste('z_time', round(z_time,4)))
print(paste('nik_time', round(nik_time,4)))
print(paste('phi_time', round(phi_time,4)))
print(paste('aux_time', round(aux_time,4)))
print(paste('beta_time', round(beta_time,4)))
print(paste('pi_time', round(pi_time,4)))
print(paste('gamma_time', round(gamma_time,4)))
print(paste('alpha_time', round(alpha_time,4)))
print(paste('impute_time', round(impute_time,4)))
print(paste('total_time', round(total_time,4)))
```
* * *



